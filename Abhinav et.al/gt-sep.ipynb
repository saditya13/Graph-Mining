{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7213467,"sourceType":"datasetVersion","datasetId":4174107}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --pre dgl -f https://data.dgl.ai/wheels-test/cu118/repo.html\n!pip install --pre dglgo -f https://data.dgl.ai/wheels-test/repo.html","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:51:38.253287Z","iopub.execute_input":"2023-12-17T09:51:38.253612Z","iopub.status.idle":"2023-12-17T09:52:47.861508Z","shell.execute_reply.started":"2023-12-17T09:51:38.253583Z","shell.execute_reply":"2023-12-17T09:52:47.860367Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: https://data.dgl.ai/wheels-test/cu118/repo.html\nCollecting dgl\n  Downloading https://data.dgl.ai/wheels-test/cu118/dgl-1.2a231216%2Bcu118-cp310-cp310-manylinux1_x86_64.whl (312.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (1.24.3)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (1.11.4)\nRequirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.10/site-packages (from dgl) (3.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from dgl) (4.66.1)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (5.9.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (2023.11.17)\nInstalling collected packages: dgl\nSuccessfully installed dgl-1.2a231216+cu118\nLooking in links: https://data.dgl.ai/wheels-test/repo.html\nCollecting dglgo\n  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (0.9.0)\nRequirement already satisfied: isort>=5.10.1 in /opt/conda/lib/python3.10/site-packages (from dglgo) (5.13.1)\nRequirement already satisfied: autopep8>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (2.0.4)\nCollecting numpydoc>=1.1.0 (from dglgo)\n  Obtaining dependency information for numpydoc>=1.1.0 from https://files.pythonhosted.org/packages/9c/94/09c437fd4a5fb5adf0468c0865c781dbc11d399544b55f1163d5d4414afb/numpydoc-1.6.0-py3-none-any.whl.metadata\n  Downloading numpydoc-1.6.0-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: pydantic>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (1.10.12)\nRequirement already satisfied: ruamel.yaml>=0.17.20 in /opt/conda/lib/python3.10/site-packages (from dglgo) (0.17.32)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from dglgo) (6.0.1)\nCollecting ogb>=1.3.3 (from dglgo)\n  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m356.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting rdkit-pypi (from dglgo)\n  Downloading rdkit_pypi-2023.3.1b1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (1.2.2)\nRequirement already satisfied: pycodestyle>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from autopep8>=1.6.0->dglgo) (2.11.1)\nRequirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\nCollecting sphinx>=5 (from numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinx>=5 from https://files.pythonhosted.org/packages/b2/b6/8ed35256aa530a9d3da15d20bdc0ba888d5364441bb50a5a83ee7827affe/sphinx-7.2.6-py3-none-any.whl.metadata\n  Downloading sphinx-7.2.6-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: Jinja2>=2.10 in /opt/conda/lib/python3.10/site-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\nRequirement already satisfied: tabulate>=0.8.10 in /opt/conda/lib/python3.10/site-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (2.0.0)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.24.3)\nRequirement already satisfied: tqdm>=4.29.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (4.66.1)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (2.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.16.0)\nRequirement already satisfied: urllib3>=1.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.26.15)\nCollecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.7)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.4.0->dglgo) (8.1.7)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit-pypi->dglgo) (10.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\nRequirement already satisfied: setuptools>=44 in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (68.1.2)\nCollecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3)\nCollecting sphinxcontrib-applehelp (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-applehelp from https://files.pythonhosted.org/packages/c0/0c/261c0949083c0ac635853528bb0070c89e927841d4e533ba0b5563365c06/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_applehelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\nCollecting sphinxcontrib-devhelp (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-devhelp from https://files.pythonhosted.org/packages/c0/03/010ac733ec7b7f71c1dc88e7115743ee466560d6d85373b56fb9916e4586/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_devhelp-1.0.5-py3-none-any.whl.metadata (2.2 kB)\nCollecting sphinxcontrib-jsmath (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\nCollecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-htmlhelp>=2.0.0 from https://files.pythonhosted.org/packages/28/7a/958f8e3e6abe8219d0d1f1224886de847ab227b218f4a07b61bc337f64be/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl.metadata (2.2 kB)\nCollecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-serializinghtml>=1.1.9 from https://files.pythonhosted.org/packages/95/d6/2e0bda62b2a808070ac922d21a950aa2cb5e4fcfb87e5ff5f86bc43a2201/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-qthelp (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-qthelp from https://files.pythonhosted.org/packages/1f/e5/1850f3f118e95581c1e30b57028ac979badee1eb29e70ee72b0241f5a185/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_qthelp-1.0.6-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\nRequirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.20.1)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.12.1)\nCollecting alabaster<0.8,>=0.7 (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)\nCollecting imagesize>=1.3 (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\nRequirement already satisfied: packaging>=21.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.0->sphinx>=5->numpydoc>=1.1.0->dglgo) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\nDownloading numpydoc-1.6.0-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinx-7.2.6-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl (92 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_applehelp-1.0.7-py3-none-any.whl (120 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_devhelp-1.0.5-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_qthelp-1.0.6-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: littleutils\n  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=4ef8446aaa36935b00d01ecd9c2864c5fa30e8e2a39e3080a84b68f7cb865566\n  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\nSuccessfully built littleutils\nInstalling collected packages: littleutils, sphinxcontrib-jsmath, rdkit-pypi, imagesize, alabaster, outdated, ogb, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinx, numpydoc, dglgo\nSuccessfully installed alabaster-0.7.13 dglgo-0.0.2 imagesize-1.4.1 littleutils-0.2.2 numpydoc-1.6.0 ogb-1.3.6 outdated-0.2.2 rdkit-pypi-2023.3.1b1 sphinx-7.2.6 sphinxcontrib-applehelp-1.0.7 sphinxcontrib-devhelp-1.0.5 sphinxcontrib-htmlhelp-2.0.4 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.6 sphinxcontrib-serializinghtml-1.1.9\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch import nn\nfrom dgl import ops\nfrom dgl.nn.functional import edge_softmax\nimport dgl\nimport tqdm\nimport os\nimport numpy as np\nfrom torch.nn import functional as F\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:52:47.863762Z","iopub.execute_input":"2023-12-17T09:52:47.864143Z","iopub.status.idle":"2023-12-17T09:52:52.193323Z","shell.execute_reply.started":"2023-12-17T09:52:47.864106Z","shell.execute_reply":"2023-12-17T09:52:52.192329Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"DGL backend not selected or invalid.  Assuming PyTorch for now.\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.__version__","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:52:52.194662Z","iopub.execute_input":"2023-12-17T09:52:52.195589Z","iopub.status.idle":"2023-12-17T09:52:52.203296Z","shell.execute_reply.started":"2023-12-17T09:52:52.195552Z","shell.execute_reply":"2023-12-17T09:52:52.202032Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'2.0.0'"},"metadata":{}}]},{"cell_type":"code","source":"!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:52:56.813970Z","iopub.execute_input":"2023-12-17T09:52:56.814901Z","iopub.status.idle":"2023-12-17T09:52:57.784732Z","shell.execute_reply.started":"2023-12-17T09:52:56.814866Z","shell.execute_reply":"2023-12-17T09:52:57.783504Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\n","output_type":"stream"}]},{"cell_type":"code","source":"class ResModule(nn.Module):\n    def __init__(self, module, normalization, dim, **kwargs):\n        super().__init__()\n        self.normalization = normalization(dim)\n        self.module = module(dim=dim, **kwargs)\n\n    def forward(self, graph, x):\n        x_res = self.normalization(x)\n        x_res = self.module(graph, x_res)\n        x = x + x_res\n\n        return x\n\n\nclass FeedForwardModule(nn.Module):\n    def __init__(self, dim, dropout, input_dim_multiplier=1, **kwargs):\n        super().__init__()\n        input_dim = int(dim * input_dim_multiplier)\n        hidden_dim = int(dim)\n        self.linear_1 = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n        self.dropout_1 = nn.Dropout(p=dropout)\n        self.act = nn.GELU()\n        self.linear_2 = nn.Linear(in_features=hidden_dim, out_features=dim)\n        self.dropout_2 = nn.Dropout(p=dropout)\n\n    def forward(self, graph, x):\n        x = self.linear_1(x)\n        x = self.dropout_1(x)\n        x = self.act(x)\n        x = self.linear_2(x)\n        x = self.dropout_2(x)\n\n        return x","metadata":{"id":"892507ec-584e-49a7-a5be-ff93f990ad4c","execution":{"iopub.status.busy":"2023-12-17T09:52:57.786795Z","iopub.execute_input":"2023-12-17T09:52:57.787156Z","iopub.status.idle":"2023-12-17T09:52:57.797129Z","shell.execute_reply.started":"2023-12-17T09:52:57.787126Z","shell.execute_reply":"2023-12-17T09:52:57.796210Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class TransformerAttentionModule(nn.Module):\n    def __init__(self, dim, num_heads, dropout, **kwargs):\n        super().__init__()\n\n        _check_dim_and_num_heads_consistency(dim, num_heads)\n        self.dim = dim\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n\n        self.attn_query = nn.Linear(in_features=dim, out_features=dim)\n        self.attn_key = nn.Linear(in_features=dim, out_features=dim)\n        self.attn_value = nn.Linear(in_features=dim, out_features=dim)\n\n        self.output_linear = nn.Linear(in_features=dim, out_features=dim)\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, graph, x):\n        queries = self.attn_query(x)\n        keys = self.attn_key(x)\n        values = self.attn_value(x)\n        queries = queries.reshape(-1, self.num_heads, self.head_dim)\n        keys = keys.reshape(-1, self.num_heads, self.head_dim)\n        values = values.reshape(-1, self.num_heads, self.head_dim)\n        attn_scores = ops.u_dot_v(graph, queries, keys) / self.head_dim ** 0.5\n        attn_probs = edge_softmax(graph, attn_scores)\n        x = ops.u_mul_e_sum(graph, values, attn_probs)\n        x = x.reshape(-1, self.dim)\n        x = self.output_linear(x)\n        x = self.dropout(x)\n        return x","metadata":{"id":"067c5f02-52dd-4d35-a714-3e8ff86d72d8","execution":{"iopub.status.busy":"2023-12-17T09:52:58.098167Z","iopub.execute_input":"2023-12-17T09:52:58.098543Z","iopub.status.idle":"2023-12-17T09:52:58.108581Z","shell.execute_reply.started":"2023-12-17T09:52:58.098513Z","shell.execute_reply":"2023-12-17T09:52:58.107546Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class TransformerAttentionSepModule(nn.Module):\n    def __init__(self, dim, num_heads, dropout, **kwargs):\n        super().__init__()\n\n        _check_dim_and_num_heads_consistency(dim, num_heads)\n        self.dim = dim\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n\n        self.attn_query = nn.Linear(in_features=dim, out_features=dim)\n        self.attn_key = nn.Linear(in_features=dim, out_features=dim)\n        self.attn_value = nn.Linear(in_features=dim, out_features=dim)\n\n        self.output_linear = nn.Linear(in_features=dim * 2, out_features=dim)\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, graph, x):\n        queries = self.attn_query(x)\n        keys = self.attn_key(x)\n        values = self.attn_value(x)\n\n        queries = queries.reshape(-1, self.num_heads, self.head_dim)\n        keys = keys.reshape(-1, self.num_heads, self.head_dim)\n        values = values.reshape(-1, self.num_heads, self.head_dim)\n\n        attn_scores = ops.u_dot_v(graph, queries, keys) / self.head_dim ** 0.5\n        attn_probs = edge_softmax(graph, attn_scores)\n\n        message = ops.u_mul_e_sum(graph, values, attn_probs)\n        message = message.reshape(-1, self.dim)\n        x = torch.cat([x, message], axis=1)\n\n        x = self.output_linear(x)\n        x = self.dropout(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:52:58.656287Z","iopub.execute_input":"2023-12-17T09:52:58.657274Z","iopub.status.idle":"2023-12-17T09:52:58.667293Z","shell.execute_reply.started":"2023-12-17T09:52:58.657239Z","shell.execute_reply":"2023-12-17T09:52:58.666355Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class GTModel(nn.Module):\n    def __init__(self,num_layers,input_dim,hidden_dim,output_dim,hidden_dim_multiplier,num_heads):\n        super().__init__()\n        \n        self.input_linear = nn.Linear(in_features=input_dim,out_features=hidden_dim)\n        self.dropout_layer = nn.Dropout(p=0.2)\n        self.activation_layer = nn.GELU()\n        self.residual_modules = nn.ModuleList()\n        for _ in range(num_layers):\n            self.residual_modules.append(ResModule(module=TransformerAttentionModule,\n                                             normalization=nn.BatchNorm1d,\n                                             dim=hidden_dim,\n                                             num_heads=num_heads,\n                                             dropout=0.2))\n            self.residual_modules.append(ResModule(module=FeedForwardModule,\n                                             normalization=nn.BatchNorm1d,\n                                             dim=hidden_dim,\n                                             num_heads=num_heads,\n                                             dropout=0.2))\n        self.output_normalization = nn.BatchNorm1d(hidden_dim)\n        self.output_linear = nn.Linear(in_features=hidden_dim,out_features=output_dim)\n    def forward(self,graph,x):\n        x = self.input_linear(x)\n        x = self.dropout_layer(x)\n        x = self.activation_layer(x)\n        for module in self.residual_modules:\n            x = module(graph,x)\n        x = self.output_normalization(x)\n        x = self.output_linear(x).squeeze(1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:52:58.827117Z","iopub.execute_input":"2023-12-17T09:52:58.827508Z","iopub.status.idle":"2023-12-17T09:52:58.837834Z","shell.execute_reply.started":"2023-12-17T09:52:58.827476Z","shell.execute_reply":"2023-12-17T09:52:58.836747Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class GTSepModel(nn.Module):\n    def __init__(self,num_layers,input_dim,hidden_dim,output_dim,hidden_dim_multiplier,num_heads):\n        super().__init__()\n        \n        self.input_linear = nn.Linear(in_features=input_dim,out_features=hidden_dim)\n        self.dropout_layer = nn.Dropout(p=0.2)\n        self.activation_layer = nn.GELU()\n        self.residual_modules = nn.ModuleList()\n        for _ in range(num_layers):\n            self.residual_modules.append(ResModule(module=TransformerAttentionSepModule,\n                                             normalization=nn.BatchNorm1d,\n                                             dim=hidden_dim,\n                                             num_heads=num_heads,\n                                             dropout=0.2))\n            self.residual_modules.append(ResModule(module=FeedForwardModule,\n                                             normalization=nn.BatchNorm1d,\n                                             dim=hidden_dim,\n                                             num_heads=num_heads,\n                                             dropout=0.2))\n        self.output_normalization = nn.BatchNorm1d(hidden_dim)\n        self.output_linear = nn.Linear(in_features=hidden_dim,out_features=output_dim)\n    def forward(self,graph,x):\n        x = self.input_linear(x)\n        x = self.dropout_layer(x)\n        x = self.activation_layer(x)\n        for module in self.residual_modules:\n            x = module(graph,x)\n        x = self.output_normalization(x)\n        x = self.output_linear(x).squeeze(1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:03:53.223142Z","iopub.execute_input":"2023-12-17T10:03:53.223608Z","iopub.status.idle":"2023-12-17T10:03:53.235523Z","shell.execute_reply.started":"2023-12-17T10:03:53.223576Z","shell.execute_reply":"2023-12-17T10:03:53.234414Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def _check_dim_and_num_heads_consistency(dim, num_heads):\n    if dim % num_heads != 0:\n        raise ValueError('Dimension mismatch: hidden_dim should be a multiple of num_heads.')","metadata":{"id":"bf30eacc-a262-4d39-b8b4-8d5781fbf88f","execution":{"iopub.status.busy":"2023-12-17T09:52:59.168462Z","iopub.execute_input":"2023-12-17T09:52:59.169192Z","iopub.status.idle":"2023-12-17T09:52:59.173673Z","shell.execute_reply.started":"2023-12-17T09:52:59.169160Z","shell.execute_reply":"2023-12-17T09:52:59.172647Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class Dataset:\n    def __init__(self, name, add_self_loops=False, device='gpu'):\n        \n        data = np.load(os.path.join('/kaggle/input/heterophily/data', f'{name.replace(\"-\", \"_\")}.npz'))\n        node_features = torch.tensor(data['node_features'])\n        labels = torch.tensor(data['node_labels'])\n        edges = torch.tensor(data['edges'])\n\n        graph = dgl.graph((edges[:, 0], edges[:, 1]), num_nodes=len(node_features), idtype=torch.int)\n        \n        if 'directed' not in name:\n            graph = dgl.to_bidirected(graph)\n\n        if add_self_loops:\n            graph = dgl.add_self_loop(graph)\n\n        num_classes = len(labels.unique())\n        num_targets = 1 if num_classes == 2 else num_classes\n        if num_targets == 1:\n            labels = labels.float()\n\n        train_masks = torch.tensor(data['train_masks'])\n        val_masks = torch.tensor(data['val_masks'])\n        test_masks = torch.tensor(data['test_masks'])\n\n        train_idx_list = [torch.where(train_mask)[0] for train_mask in train_masks]\n        val_idx_list = [torch.where(val_mask)[0] for val_mask in val_masks]\n        test_idx_list = [torch.where(test_mask)[0] for test_mask in test_masks]\n\n        self.name = name\n        self.device = device\n\n        self.graph = graph.to(device)\n        self.node_features = node_features.to(device)\n        self.labels = labels.to(device)\n\n        self.train_idx_list = [train_idx.to(device) for train_idx in train_idx_list]\n        self.val_idx_list = [val_idx.to(device) for val_idx in val_idx_list]\n        self.test_idx_list = [test_idx.to(device) for test_idx in test_idx_list]\n        self.num_data_splits = len(train_idx_list)\n        self.cur_data_split = 0\n\n        self.num_node_features = node_features.shape[1]\n        self.num_targets = num_targets\n\n        self.loss_fn = F.binary_cross_entropy_with_logits if num_targets == 1 else F.cross_entropy\n        self.metric = 'accuracy'\n\n    @property\n    def train_idx(self):\n        return self.train_idx_list[self.cur_data_split]\n\n    @property\n    def val_idx(self):\n        return self.val_idx_list[self.cur_data_split]\n\n    @property\n    def test_idx(self):\n        return self.test_idx_list[self.cur_data_split]\n\n    def next_data_split(self):\n        self.cur_data_split = (self.cur_data_split + 1) % self.num_data_splits\n\n    def compute_metrics(self, logits):\n        if self.num_targets == 1:\n            train_metric = roc_auc_score(y_true=self.labels[self.train_idx].cpu().numpy(),\n                                         y_score=logits[self.train_idx].cpu().numpy()).item()\n\n            val_metric = roc_auc_score(y_true=self.labels[self.val_idx].cpu().numpy(),\n                                       y_score=logits[self.val_idx].cpu().numpy()).item()\n\n            test_metric = roc_auc_score(y_true=self.labels[self.test_idx].cpu().numpy(),\n                                        y_score=logits[self.test_idx].cpu().numpy()).item()\n\n        else:\n            preds = logits.argmax(axis=1)\n            train_metric = (preds[self.train_idx] == self.labels[self.train_idx]).float().mean().item()\n            val_metric = (preds[self.val_idx] == self.labels[self.val_idx]).float().mean().item()\n            test_metric = (preds[self.test_idx] == self.labels[self.test_idx]).float().mean().item()\n\n        metrics = {\n            f'train {self.metric}': train_metric,\n            f'val {self.metric}': val_metric,\n            f'test {self.metric}': test_metric\n        }\n\n        return metrics\n","metadata":{"id":"c18b0dd0-1a6f-43cb-a11c-2b033d8bb4d7","execution":{"iopub.status.busy":"2023-12-17T09:52:59.346459Z","iopub.execute_input":"2023-12-17T09:52:59.347093Z","iopub.status.idle":"2023-12-17T09:52:59.367400Z","shell.execute_reply.started":"2023-12-17T09:52:59.347061Z","shell.execute_reply":"2023-12-17T09:52:59.366440Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")","metadata":{"id":"bc4488b2-2eeb-455d-9d30-d81c1c1519bf","execution":{"iopub.status.busy":"2023-12-17T09:52:59.857594Z","iopub.execute_input":"2023-12-17T09:52:59.858529Z","iopub.status.idle":"2023-12-17T09:52:59.862677Z","shell.execute_reply.started":"2023-12-17T09:52:59.858495Z","shell.execute_reply":"2023-12-17T09:52:59.861759Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dataset = Dataset(name=\"roman-empire\",\n                 add_self_loops=True,\n                 device=device)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47ac5e49-656c-4bfe-823f-4b9b783051d3","outputId":"ca434010-a3dc-49ed-ebfe-101928b63639","execution":{"iopub.status.busy":"2023-12-17T09:53:00.071614Z","iopub.execute_input":"2023-12-17T09:53:00.071971Z","iopub.status.idle":"2023-12-17T09:53:04.274305Z","shell.execute_reply.started":"2023-12-17T09:53:00.071942Z","shell.execute_reply":"2023-12-17T09:53:04.273484Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# model = Model(model_name=\"GT-sep\",num_layers=5,input_dim=dataset.num_node_features,\n#              hidden_dim=512,output_dim=dataset.num_targets,\n#              hidden_dim_multiplier=1,num_heads=8,normalization='BatchNorm',\n#              dropout=0.2)","metadata":{"id":"3f6fee87-b93e-4104-b4a0-a11f7a31d522","execution":{"iopub.status.busy":"2023-12-17T09:53:04.275979Z","iopub.execute_input":"2023-12-17T09:53:04.276319Z","iopub.status.idle":"2023-12-17T09:53:04.280458Z","shell.execute_reply.started":"2023-12-17T09:53:04.276294Z","shell.execute_reply":"2023-12-17T09:53:04.279393Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = GTModel(num_layers=5,input_dim=dataset.num_node_features,\n                   hidden_dim=512,output_dim=dataset.num_targets,\n                   hidden_dim_multiplier=1,num_heads=8)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T09:53:04.281533Z","iopub.execute_input":"2023-12-17T09:53:04.281836Z","iopub.status.idle":"2023-12-17T09:53:04.368652Z","shell.execute_reply.started":"2023-12-17T09:53:04.281812Z","shell.execute_reply":"2023-12-17T09:53:04.367744Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train_step(model, dataset, optimizer, scheduler, scaler, amp=False):\n    model.train()\n\n    with autocast(enabled=amp):\n        logits = model(graph=dataset.graph, x=dataset.node_features)\n        loss = dataset.loss_fn(input=logits[dataset.train_idx], target=dataset.labels[dataset.train_idx])\n\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n    optimizer.zero_grad()\n    scheduler.step()\n\n\n@torch.no_grad()\ndef evaluate(model, dataset, amp=False):\n    model.eval()\n    with autocast(enabled=amp):\n        logits = model(graph=dataset.graph, x=dataset.node_features)\n    metrics = dataset.compute_metrics(logits)\n    return metrics","metadata":{"id":"022895a2-1464-401e-adbd-1d43b33a57bf","execution":{"iopub.status.busy":"2023-12-17T09:53:04.371065Z","iopub.execute_input":"2023-12-17T09:53:04.371397Z","iopub.status.idle":"2023-12-17T09:53:04.379638Z","shell.execute_reply.started":"2023-12-17T09:53:04.371370Z","shell.execute_reply":"2023-12-17T09:53:04.378566Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def get_parameter_groups(model):\n    no_weight_decay_names = ['bias', 'normalization', 'label_embeddings']\n    parameter_groups = [\n        {\n            'params': [param for name, param in model.named_parameters()\n                       if not any(no_weight_decay_name in name for no_weight_decay_name in no_weight_decay_names)]\n        },\n        {\n            'params': [param for name, param in model.named_parameters()\n                       if any(no_weight_decay_name in name for no_weight_decay_name in no_weight_decay_names)],\n            'weight_decay': 0\n        },\n    ]\n    return parameter_groups\ndef get_lr_scheduler_with_warmup(optimizer, num_warmup_steps=None, num_steps=None, warmup_proportion=None,\n                                 last_step=-1):\n\n\n    if num_warmup_steps is None:\n        num_warmup_steps = int(num_steps * warmup_proportion)\n\n    def get_lr_multiplier(step):\n        if step < num_warmup_steps:\n            return (step + 1) / (num_warmup_steps + 1)\n        else:\n            return 1\n\n    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_multiplier, last_epoch=last_step)\n\n    return lr_scheduler","metadata":{"id":"b59c4eae-6670-42b8-a783-df1df290e39f","execution":{"iopub.status.busy":"2023-12-17T09:53:04.380962Z","iopub.execute_input":"2023-12-17T09:53:04.381290Z","iopub.status.idle":"2023-12-17T09:53:04.392254Z","shell.execute_reply.started":"2023-12-17T09:53:04.381264Z","shell.execute_reply":"2023-12-17T09:53:04.391532Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.to(torch.device(\"cuda:0\"))","metadata":{"id":"d85de6c6-38d5-43c9-9d6f-de4241edf984","outputId":"5488bc40-4627-40f7-e905-271f9841646e","execution":{"iopub.status.busy":"2023-12-17T09:53:04.393717Z","iopub.execute_input":"2023-12-17T09:53:04.394339Z","iopub.status.idle":"2023-12-17T09:53:04.424936Z","shell.execute_reply.started":"2023-12-17T09:53:04.394300Z","shell.execute_reply":"2023-12-17T09:53:04.424054Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"GTModel(\n  (input_linear): Linear(in_features=300, out_features=512, bias=True)\n  (dropout_layer): Dropout(p=0.2, inplace=False)\n  (activation_layer): GELU(approximate='none')\n  (residual_modules): ModuleList(\n    (0): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): TransformerAttentionModule(\n        (attn_query): Linear(in_features=512, out_features=512, bias=True)\n        (attn_key): Linear(in_features=512, out_features=512, bias=True)\n        (attn_value): Linear(in_features=512, out_features=512, bias=True)\n        (output_linear): Linear(in_features=512, out_features=512, bias=True)\n        (dropout): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (1): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): FeedForwardModule(\n        (linear_1): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_1): Dropout(p=0.2, inplace=False)\n        (act): GELU(approximate='none')\n        (linear_2): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_2): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (2): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): TransformerAttentionModule(\n        (attn_query): Linear(in_features=512, out_features=512, bias=True)\n        (attn_key): Linear(in_features=512, out_features=512, bias=True)\n        (attn_value): Linear(in_features=512, out_features=512, bias=True)\n        (output_linear): Linear(in_features=512, out_features=512, bias=True)\n        (dropout): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (3): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): FeedForwardModule(\n        (linear_1): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_1): Dropout(p=0.2, inplace=False)\n        (act): GELU(approximate='none')\n        (linear_2): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_2): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (4): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): TransformerAttentionModule(\n        (attn_query): Linear(in_features=512, out_features=512, bias=True)\n        (attn_key): Linear(in_features=512, out_features=512, bias=True)\n        (attn_value): Linear(in_features=512, out_features=512, bias=True)\n        (output_linear): Linear(in_features=512, out_features=512, bias=True)\n        (dropout): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (5): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): FeedForwardModule(\n        (linear_1): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_1): Dropout(p=0.2, inplace=False)\n        (act): GELU(approximate='none')\n        (linear_2): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_2): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (6): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): TransformerAttentionModule(\n        (attn_query): Linear(in_features=512, out_features=512, bias=True)\n        (attn_key): Linear(in_features=512, out_features=512, bias=True)\n        (attn_value): Linear(in_features=512, out_features=512, bias=True)\n        (output_linear): Linear(in_features=512, out_features=512, bias=True)\n        (dropout): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (7): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): FeedForwardModule(\n        (linear_1): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_1): Dropout(p=0.2, inplace=False)\n        (act): GELU(approximate='none')\n        (linear_2): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_2): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (8): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): TransformerAttentionModule(\n        (attn_query): Linear(in_features=512, out_features=512, bias=True)\n        (attn_key): Linear(in_features=512, out_features=512, bias=True)\n        (attn_value): Linear(in_features=512, out_features=512, bias=True)\n        (output_linear): Linear(in_features=512, out_features=512, bias=True)\n        (dropout): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (9): ResModule(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): FeedForwardModule(\n        (linear_1): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_1): Dropout(p=0.2, inplace=False)\n        (act): GELU(approximate='none')\n        (linear_2): Linear(in_features=512, out_features=512, bias=True)\n        (dropout_2): Dropout(p=0.2, inplace=False)\n      )\n    )\n  )\n  (output_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (output_linear): Linear(in_features=512, out_features=18, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"parameter_groups = get_parameter_groups(model)\noptimizer = torch.optim.AdamW(parameter_groups, lr=3e-5, weight_decay=0)\nscheduler = get_lr_scheduler_with_warmup(optimizer=optimizer, num_warmup_steps=None,\n                                                 num_steps=500, warmup_proportion=0)","metadata":{"id":"2c413707-d09b-418d-aefb-8095dd8b1b89","execution":{"iopub.status.busy":"2023-12-17T09:53:04.426026Z","iopub.execute_input":"2023-12-17T09:53:04.426354Z","iopub.status.idle":"2023-12-17T09:53:04.432806Z","shell.execute_reply.started":"2023-12-17T09:53:04.426328Z","shell.execute_reply":"2023-12-17T09:53:04.431850Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for run in range(1):\n    with tqdm.tqdm(total=500, desc=f'Run {run}', disable=False) as progress_bar:\n                for step in range(1, 500 + 1):\n                    train_step(model=model, dataset=dataset, optimizer=optimizer, scheduler=scheduler,scaler= GradScaler(enabled=True))\n                    metrics = evaluate(model=model, dataset=dataset, amp=False)\n                    progress_bar.update()\n                    progress_bar.set_postfix({metric: f'{value:.2f}' for metric, value in metrics.items()})","metadata":{"id":"5937f5a4-c27f-430d-9074-a3bcc3d4b849","outputId":"bf074513-d176-44d4-c11d-de3b1fa45026","execution":{"iopub.status.busy":"2023-12-17T09:53:04.434171Z","iopub.execute_input":"2023-12-17T09:53:04.434504Z","iopub.status.idle":"2023-12-17T09:55:31.849103Z","shell.execute_reply.started":"2023-12-17T09:53:04.434473Z","shell.execute_reply":"2023-12-17T09:55:31.848104Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [02:27<00:00,  3.39it/s, train accuracy=0.96, val accuracy=0.82, test accuracy=0.80]\n","output_type":"stream"}]},{"cell_type":"code","source":"datasets = [\"squirrel\",\"squirrel-filtered\",\"chameleon\",\"chameleon_filtered\",\"roman-empire\",\"minesweeper\",\"amazon-ratings\",\"questions\",\"tolokers\"]\nfor dataset_name in datasets:\n    dataset = Dataset(name=dataset_name,\n                 add_self_loops=True,\n                 device=device)\n    model = GTSepModel(num_layers=5,input_dim=dataset.num_node_features,\n                   hidden_dim=512,output_dim=dataset.num_targets,\n                   hidden_dim_multiplier=1,num_heads=8)\n    model.to(torch.device(\"cuda:0\"))\n    parameter_groups = get_parameter_groups(model)\n    optimizer = torch.optim.AdamW(parameter_groups, lr=3e-5, weight_decay=0)\n    scheduler = get_lr_scheduler_with_warmup(optimizer=optimizer, num_warmup_steps=None,\n                                                     num_steps=500, warmup_proportion=0)\n    print(\"Running for:\",dataset_name)\n    for run in range(1):\n        with tqdm.tqdm(total=500, desc=f'Run {run}', disable=False) as progress_bar:\n                    for step in range(1, 500 + 1):\n                        train_step(model=model, dataset=dataset, optimizer=optimizer, scheduler=scheduler,scaler= GradScaler(enabled=True))\n                        metrics = evaluate(model=model, dataset=dataset, amp=False)\n                        progress_bar.update()\n                        progress_bar.set_postfix({metric: f'{value:.2f}' for metric, value in metrics.items()})","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:06:36.753673Z","iopub.execute_input":"2023-12-17T10:06:36.754590Z","iopub.status.idle":"2023-12-17T10:27:53.369809Z","shell.execute_reply.started":"2023-12-17T10:06:36.754553Z","shell.execute_reply":"2023-12-17T10:27:53.368704Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Running for: squirrel\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [01:46<00:00,  4.71it/s, train accuracy=1.00, val accuracy=0.39, test accuracy=0.40]\n","output_type":"stream"},{"name":"stdout","text":"Running for: squirrel-filtered\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [00:36<00:00, 13.62it/s, train accuracy=1.00, val accuracy=0.32, test accuracy=0.33]\n","output_type":"stream"},{"name":"stdout","text":"Running for: chameleon\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [00:33<00:00, 14.81it/s, train accuracy=1.00, val accuracy=0.50, test accuracy=0.49]\n","output_type":"stream"},{"name":"stdout","text":"Running for: chameleon_filtered\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [00:21<00:00, 23.07it/s, train accuracy=1.00, val accuracy=0.37, test accuracy=0.34]\n","output_type":"stream"},{"name":"stdout","text":"Running for: roman-empire\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [02:43<00:00,  3.07it/s, train accuracy=0.99, val accuracy=0.84, test accuracy=0.83]\n","output_type":"stream"},{"name":"stdout","text":"Running for: minesweeper\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [01:25<00:00,  5.82it/s, train accuracy=0.96, val accuracy=0.91, test accuracy=0.92]\n","output_type":"stream"},{"name":"stdout","text":"Running for: amazon-ratings\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [03:12<00:00,  2.60it/s, train accuracy=0.82, val accuracy=0.50, test accuracy=0.51]\n","output_type":"stream"},{"name":"stdout","text":"Running for: questions\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [06:21<00:00,  1.31it/s, train accuracy=0.79, val accuracy=0.71, test accuracy=0.71]\n","output_type":"stream"},{"name":"stdout","text":"Running for: tolokers\n","output_type":"stream"},{"name":"stderr","text":"Run 0: 100%|██████████| 500/500 [04:01<00:00,  2.07it/s, train accuracy=0.91, val accuracy=0.82, test accuracy=0.84]\n","output_type":"stream"}]}]}