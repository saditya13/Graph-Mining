{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDt1Ph6bweWm",
        "outputId": "e6a417af-ad27-4364-da72-6603489fc4fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch import Tensor\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "82wLdSnzdG5q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(pr_logits, gt_labels):\n",
        "    return (pr_logits.argmax(dim=-1) == gt_labels).float().mean().item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def roc_auc(pr_logits, gt_labels):\n",
        "    return roc_auc_score(gt_labels.cpu().numpy(), pr_logits[:, 1].cpu().numpy())\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def zero_in_degree_removal(data):\n",
        "    edge_index = data.edge_index\n",
        "    # keep only with non-zero incoming edges\n",
        "    valid_ids = torch.unique(edge_index[1])\n",
        "    node_mask = torch.zeros(len(data.y), dtype=torch.bool)\n",
        "    node_mask[valid_ids] = True\n",
        "    valid_mask = edge_index[0].clone().apply_(lambda x: x in valid_ids).bool()\n",
        "    valid_edges = torch.masked_select(data.edge_index, valid_mask).view(2, -1)\n",
        "    return Data(\n",
        "        x=data.x,\n",
        "        y=data.y,\n",
        "        edge_index=valid_edges,\n",
        "        train_mask=(data.train_mask & node_mask[:, None]),\n",
        "        val_mask=(data.val_mask & node_mask[:, None]),\n",
        "        test_mask=(data.test_mask & node_mask[:, None]),\n",
        "    )"
      ],
      "metadata": {
        "id": "tcIdB37Wut1L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__all__ = ['train_step', 'val_step']\n",
        "\n",
        "\n",
        "def train_step(\n",
        "    model,\n",
        "    optimizer,\n",
        "    labels,\n",
        "    list_mat,\n",
        "    mask,\n",
        "    metric = accuracy,\n",
        "    device: str = 'cpu'\n",
        "):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(list_mat)\n",
        "    loss_train = F.cross_entropy(output[mask], labels[mask].to(device))\n",
        "    acc_train = metric(output[mask], labels[mask].to(device))\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    return loss_train, acc_train\n",
        "\n",
        "\n",
        "def val_step(\n",
        "    model,\n",
        "    labels,\n",
        "    list_mat,\n",
        "    mask,\n",
        "    metric = accuracy,\n",
        "    device: str = 'cpu'\n",
        "):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(list_mat)\n",
        "        loss_val = F.cross_entropy(output[mask], labels[mask].to(device))\n",
        "        acc_val = metric(output[mask], labels[mask].to(device))\n",
        "        return loss_val, acc_val"
      ],
      "metadata": {
        "id": "ZkMRmaFkufiT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "__all__ = [\n",
        "    \"FSGNN\",\n",
        "    \"FSGNN_Large\"\n",
        "]\n",
        "\n",
        "\n",
        "class FSGNN(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nfeat,\n",
        "        nlayers,\n",
        "        nhidden,\n",
        "        nclass,\n",
        "        dropout,\n",
        "        layer_norm: bool = False,\n",
        "    ):\n",
        "        super(FSGNN, self).__init__()\n",
        "        self.fc2 = nn.Linear(nhidden * nlayers,nclass)\n",
        "        self.dropout = dropout\n",
        "        self.act_fn = nn.ReLU()\n",
        "        self.fc1 = nn.ModuleList([nn.Linear(nfeat,int(nhidden)) for _ in range(nlayers)])\n",
        "        self.att = nn.Parameter(torch.ones(nlayers))\n",
        "        self.sm = nn.Softmax(dim=0)\n",
        "        self.layer_norm = layer_norm\n",
        "\n",
        "    def forward(self, list_mat):\n",
        "        mask = self.sm(self.att)\n",
        "        list_out = list()\n",
        "        for ind, mat in enumerate(list_mat):\n",
        "            tmp_out = self.fc1[ind](mat)\n",
        "            if self.layer_norm == True:\n",
        "                tmp_out = F.normalize(tmp_out, p=2, dim=1)\n",
        "            tmp_out = torch.mul(mask[ind],tmp_out)\n",
        "            list_out.append(tmp_out)\n",
        "\n",
        "        final_mat = torch.cat(list_out, dim=1)\n",
        "        out = self.act_fn(final_mat)\n",
        "        out = F.dropout(out,self.dropout,training=self.training)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class FSGNN_Large(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nfeat,\n",
        "        nlayers,\n",
        "        nhidden,\n",
        "        nclass,\n",
        "        dp1,\n",
        "        dp2,\n",
        "        layer_norm: bool = True\n",
        "    ):\n",
        "        super(FSGNN_Large,self).__init__()\n",
        "        self.wt1 = nn.ModuleList([nn.Linear(nfeat,int(nhidden)) for _ in range(nlayers)])\n",
        "        self.fc2 = nn.Linear(nhidden*nlayers,nhidden)\n",
        "        self.fc3 = nn.Linear(nhidden,nclass)\n",
        "        self.dropout1 = dp1\n",
        "        self.dropout2 = dp2\n",
        "        self.act_fn = nn.ReLU()\n",
        "        self.att = nn.Parameter(torch.ones(nlayers))\n",
        "        self.sm = nn.Softmax(dim=0)\n",
        "        self.layer_norm = layer_norm\n",
        "\n",
        "\n",
        "    def forward(self, list_adj, st=0, end=0):\n",
        "\n",
        "        mask = self.sm(self.att)\n",
        "        mask = torch.mul(len(list_adj),mask)\n",
        "\n",
        "        list_out = list()\n",
        "        for ind, mat in enumerate(list_adj):\n",
        "            mat = mat[st:end,:].cuda()\n",
        "            tmp_out = self.wt1[ind](mat)\n",
        "            if self.layer_norm == True:\n",
        "                tmp_out = F.normalize(tmp_out,p=2,dim=1)\n",
        "            tmp_out = torch.mul(mask[ind],tmp_out)\n",
        "\n",
        "            list_out.append(tmp_out)\n",
        "\n",
        "        final_mat = torch.cat(list_out, dim=1)\n",
        "\n",
        "        out = self.act_fn(final_mat)\n",
        "        out = F.dropout(out,self.dropout1,training=self.training)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        out = self.act_fn(out)\n",
        "        out = F.dropout(out,self.dropout2,training=self.training)\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "0UUffWd6uGsP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuGrt-cCtbxm",
        "outputId": "4d59a98d-ab63-4b1a-b226-73dd55b8b701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'seed': 42, 'steps': 1500, 'log_freq': 100, 'num_layers': 3, 'hidden_dim': 64, 'patience': 100, 'layer_norm': 1, 'lr': 0.001, 'weight_decay': 1e-05, 'dropout': 0.5, 'feat_type': 'all'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_9.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split [1/10]\n",
            "Train metric 0.142 / Val acc 0.525\n",
            "Train metric 0.900 / Val acc 0.675\n",
            "Test accuracy 0.588\n",
            "Split [2/10]\n",
            "Train metric 0.008 / Val acc 0.113\n",
            "Train metric 0.917 / Val acc 0.613\n",
            "Test accuracy 0.784\n",
            "Split [3/10]\n",
            "Train metric 0.392 / Val acc 0.488\n",
            "Train metric 0.825 / Val acc 0.562\n",
            "Test accuracy 0.549\n",
            "Split [4/10]\n",
            "Train metric 0.167 / Val acc 0.300\n",
            "Train metric 0.875 / Val acc 0.637\n",
            "Train metric 0.933 / Val acc 0.675\n",
            "Test accuracy 0.667\n",
            "Split [5/10]\n",
            "Train metric 0.225 / Val acc 0.575\n",
            "Train metric 0.892 / Val acc 0.588\n",
            "Test accuracy 0.627\n",
            "Split [6/10]\n",
            "Train metric 0.142 / Val acc 0.287\n",
            "Train metric 0.900 / Val acc 0.550\n",
            "Test accuracy 0.706\n",
            "Split [7/10]\n",
            "Train metric 0.042 / Val acc 0.175\n",
            "Train metric 0.900 / Val acc 0.650\n",
            "Test accuracy 0.686\n",
            "Split [8/10]\n",
            "Train metric 0.092 / Val acc 0.263\n",
            "Train metric 0.892 / Val acc 0.700\n",
            "Test accuracy 0.706\n",
            "Split [9/10]\n",
            "Train metric 0.050 / Val acc 0.200\n",
            "Train metric 0.875 / Val acc 0.588\n",
            "Test accuracy 0.549\n",
            "Split [10/10]\n",
            "Train metric 0.233 / Val acc 0.225\n",
            "Train metric 0.842 / Val acc 0.538\n",
            "Test accuracy 0.608\n",
            "Test accuracy 64.71 +- 7.23\n"
          ]
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "from torch_geometric.utils import to_dense_adj, add_self_loops\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Actor, WikipediaNetwork, WebKB\n",
        "\n",
        "\n",
        "DATASET_LIST = [\n",
        "    'squirrel_directed', 'chameleon_directed', 'chameleon_filtered', 'squirrel_filtered',\n",
        "    'squirrel_filtered_directed', 'chameleon_filtered_directed', 'wisconsin',\n",
        "    'roman_empire', 'minesweeper', 'questions', 'amazon_ratings', 'tolokers'\n",
        "]\n",
        "\n",
        "\n",
        "def load_custom_data(data_path, to_undirected: bool = True):\n",
        "    npz_data = np.load(data_path)\n",
        "    # convert graph to bidirectional\n",
        "    if to_undirected:\n",
        "        edges = np.concatenate((npz_data['edges'], npz_data['edges'][:, ::-1]), axis=0)\n",
        "    else:\n",
        "        edges = npz_data['edges']\n",
        "\n",
        "    data = Data(\n",
        "        x=torch.from_numpy(npz_data['node_features']),\n",
        "        y=torch.from_numpy(npz_data['node_labels']),\n",
        "        edge_index=torch.from_numpy(edges).T,\n",
        "        train_mask=torch.from_numpy(npz_data['train_masks']).T,\n",
        "        val_mask=torch.from_numpy(npz_data['val_masks']).T,\n",
        "        test_mask=torch.from_numpy(npz_data['test_masks']).T,\n",
        "    )\n",
        "    return [data]\n",
        "\n",
        "\n",
        "def get_dataset(dataset):\n",
        "    if dataset == 'actor':\n",
        "        return Actor(root='./pyg_data/actor')\n",
        "    if dataset == 'squirrel':\n",
        "        return WikipediaNetwork(root='./pyg_data', name='squirrel')\n",
        "    if dataset == 'chameleon':\n",
        "        return WikipediaNetwork(root='./pyg_data', name='chameleon')\n",
        "    if dataset in ['cornell', 'texas', 'wisconsin']:\n",
        "        return WebKB(root='./pyg_data', name=dataset)\n",
        "    if dataset in DATASET_LIST:\n",
        "        if dataset == 'chameleon_directed' or 'chameleon_filtered_directed' or 'squirrel_directed' or 'squirrel_filtered_directed':\n",
        "          return load_custom_data(\n",
        "              f'./{dataset}.npz',\n",
        "              False\n",
        "            )\n",
        "        else:\n",
        "          return load_custom_data(\n",
        "              f'./{dataset}.npz',\n",
        "              True\n",
        "          )\n",
        "    raise ValueError(\"Unknown dataset\")\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    # Training settings\n",
        "    args = dict()\n",
        "    args['seed'] = 42\n",
        "    args['steps'] = 1500\n",
        "    args['log_freq'] = 100\n",
        "    args['num_layers'] = 3\n",
        "    args['hidden_dim'] = 64\n",
        "    args['patience'] =100\n",
        "    args['layer_norm'] = 1\n",
        "    args['lr'] = 0.001\n",
        "    args['weight_decay'] = 1e-5\n",
        "    args['dropout'] = 0.5\n",
        "    args['feat_type'] = \"all\"\n",
        "    print(args)\n",
        "    return args\n",
        "\n",
        "\n",
        "def run_on_split(\n",
        "    features,\n",
        "    labels,\n",
        "    list_mat,\n",
        "    train_mask,\n",
        "    val_mask,\n",
        "    test_mask,\n",
        "    args\n",
        "):\n",
        "    num_features = features.shape[1]\n",
        "    num_labels = len(torch.unique(labels))\n",
        "\n",
        "    model = FSGNN(\n",
        "        nfeat=num_features,\n",
        "        nlayers=len(list_mat),\n",
        "        nhidden=args['hidden_dim'],\n",
        "        nclass=num_labels,\n",
        "        dropout=args['dropout'],\n",
        "        layer_norm=args['layer_norm'],\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "\n",
        "    metric = accuracy if len(torch.unique(labels)) > 2 else roc_auc\n",
        "\n",
        "    best = -torch.inf\n",
        "    best_params = None\n",
        "    bad_counter = 0\n",
        "    for step in range(args['steps']):\n",
        "        loss_train, metric_train = train_step(model, optimizer, labels, list_mat, train_mask, metric, device=device)\n",
        "        loss_val, metric_val = val_step(model, labels, list_mat, val_mask, metric, device=device)\n",
        "\n",
        "        if step % args['log_freq'] == 0:\n",
        "            print(f'Train metric {metric_train:.3f} / Val acc {metric_val:.3f}')\n",
        "\n",
        "        if metric_val > best:\n",
        "            best = metric_val\n",
        "            bad_counter = 0\n",
        "            best_params = deepcopy(model.state_dict())\n",
        "        else:\n",
        "            bad_counter += 1\n",
        "\n",
        "        if bad_counter == args['patience']:\n",
        "            break\n",
        "    # load best params\n",
        "    model.load_state_dict(best_params)\n",
        "    loss_test, metric_test = val_step(model, labels, list_mat, test_mask, metric, device=device)\n",
        "    # return test accuracy\n",
        "    return metric_test\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = parse_args()\n",
        "    # fix seeds\n",
        "    random.seed(args['seed'])\n",
        "    np.random.seed(args['seed'])\n",
        "    torch.manual_seed(args['seed'])\n",
        "    # get device\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # get dataset\n",
        "    dataset = 'wisconsin'\n",
        "    dataset = get_dataset(dataset)\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    features = data.x\n",
        "    labels = data.y\n",
        "    # get adjacency matrix and its powers\n",
        "    adj = to_dense_adj(data.edge_index)[0]\n",
        "    adj_i = to_dense_adj(add_self_loops(data.edge_index)[0])[0]\n",
        "\n",
        "    list_mat = []\n",
        "    list_mat.append(features)\n",
        "    no_loop_mat = features\n",
        "    loop_mat = features\n",
        "\n",
        "    for ii in range(args['num_layers']):\n",
        "        no_loop_mat = torch.spmm(adj, no_loop_mat)\n",
        "        loop_mat = torch.spmm(adj_i, loop_mat)\n",
        "        list_mat.append(no_loop_mat)\n",
        "        list_mat.append(loop_mat)\n",
        "\n",
        "    # Select X and self-looped features\n",
        "    if args['feat_type'] == \"homophily\":\n",
        "        select_idx = [0] + [2 * ll for ll in range(1, args.num_layers + 1)]\n",
        "        list_mat = [list_mat[ll] for ll in select_idx]\n",
        "\n",
        "    #Select X and no-loop features\n",
        "    elif args['feat_type'] == \"heterophily\":\n",
        "        select_idx = [0] + [2*ll - 1 for ll in range(1, args.num_layers + 1)]\n",
        "        list_mat = [list_mat[ll] for ll in select_idx]\n",
        "\n",
        "    num_splits = data.train_mask.shape[1]\n",
        "    test_accs = []\n",
        "    for i in range(num_splits):\n",
        "        print(f'Split [{i+1}/{num_splits}]')\n",
        "        train_mask, val_mask, test_mask = \\\n",
        "            data.train_mask[:, i], data.val_mask[:, i], data.test_mask[:, i]\n",
        "        test_acc = run_on_split(features, labels, list_mat, train_mask, val_mask, test_mask, args)\n",
        "        print(f'Test accuracy {test_acc:.3f}')\n",
        "        test_accs.append(100 * test_acc)\n",
        "\n",
        "    print(f'Test accuracy {np.mean(test_accs):.2f} +- {np.std(test_accs):.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "no6yKiwYEBOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uGYIhY7FECTf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}