{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7213467,"sourceType":"datasetVersion","datasetId":4174107},{"sourceId":7214940,"sourceType":"datasetVersion","datasetId":4175130},{"sourceId":7220912,"sourceType":"datasetVersion","datasetId":4179436},{"sourceId":7220985,"sourceType":"datasetVersion","datasetId":4179489},{"sourceId":7220999,"sourceType":"datasetVersion","datasetId":4179500},{"sourceId":7221018,"sourceType":"datasetVersion","datasetId":4179515},{"sourceId":7221414,"sourceType":"datasetVersion","datasetId":4179801}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --pre dgl -f https://data.dgl.ai/wheels-test/cu118/repo.html\n!pip install --pre dglgo -f https://data.dgl.ai/wheels-test/repo.html","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:27:11.828340Z","iopub.execute_input":"2023-12-17T11:27:11.829086Z","iopub.status.idle":"2023-12-17T11:28:09.475960Z","shell.execute_reply.started":"2023-12-17T11:27:11.829050Z","shell.execute_reply":"2023-12-17T11:28:09.474807Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: https://data.dgl.ai/wheels-test/cu118/repo.html\nCollecting dgl\n  Downloading https://data.dgl.ai/wheels-test/cu118/dgl-1.2a231216%2Bcu118-cp310-cp310-manylinux1_x86_64.whl (312.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (1.24.3)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (1.11.4)\nRequirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.10/site-packages (from dgl) (3.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from dgl) (4.66.1)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from dgl) (5.9.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (2023.11.17)\nInstalling collected packages: dgl\nSuccessfully installed dgl-1.2a231216+cu118\nLooking in links: https://data.dgl.ai/wheels-test/repo.html\nCollecting dglgo\n  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (0.9.0)\nRequirement already satisfied: isort>=5.10.1 in /opt/conda/lib/python3.10/site-packages (from dglgo) (5.13.1)\nRequirement already satisfied: autopep8>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (2.0.4)\nCollecting numpydoc>=1.1.0 (from dglgo)\n  Obtaining dependency information for numpydoc>=1.1.0 from https://files.pythonhosted.org/packages/9c/94/09c437fd4a5fb5adf0468c0865c781dbc11d399544b55f1163d5d4414afb/numpydoc-1.6.0-py3-none-any.whl.metadata\n  Downloading numpydoc-1.6.0-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: pydantic>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (1.10.12)\nRequirement already satisfied: ruamel.yaml>=0.17.20 in /opt/conda/lib/python3.10/site-packages (from dglgo) (0.17.32)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from dglgo) (6.0.1)\nCollecting ogb>=1.3.3 (from dglgo)\n  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting rdkit-pypi (from dglgo)\n  Downloading rdkit_pypi-2023.3.1b1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from dglgo) (1.2.2)\nRequirement already satisfied: pycodestyle>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from autopep8>=1.6.0->dglgo) (2.11.1)\nRequirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\nCollecting sphinx>=5 (from numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinx>=5 from https://files.pythonhosted.org/packages/b2/b6/8ed35256aa530a9d3da15d20bdc0ba888d5364441bb50a5a83ee7827affe/sphinx-7.2.6-py3-none-any.whl.metadata\n  Downloading sphinx-7.2.6-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: Jinja2>=2.10 in /opt/conda/lib/python3.10/site-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\nRequirement already satisfied: tabulate>=0.8.10 in /opt/conda/lib/python3.10/site-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (2.0.0)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.24.3)\nRequirement already satisfied: tqdm>=4.29.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (4.66.1)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (2.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.16.0)\nRequirement already satisfied: urllib3>=1.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb>=1.3.3->dglgo) (1.26.15)\nCollecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.7)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.4.0->dglgo) (8.1.7)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit-pypi->dglgo) (10.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\nRequirement already satisfied: setuptools>=44 in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (68.1.2)\nCollecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3)\nCollecting sphinxcontrib-applehelp (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-applehelp from https://files.pythonhosted.org/packages/c0/0c/261c0949083c0ac635853528bb0070c89e927841d4e533ba0b5563365c06/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_applehelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\nCollecting sphinxcontrib-devhelp (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-devhelp from https://files.pythonhosted.org/packages/c0/03/010ac733ec7b7f71c1dc88e7115743ee466560d6d85373b56fb9916e4586/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_devhelp-1.0.5-py3-none-any.whl.metadata (2.2 kB)\nCollecting sphinxcontrib-jsmath (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\nCollecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-htmlhelp>=2.0.0 from https://files.pythonhosted.org/packages/28/7a/958f8e3e6abe8219d0d1f1224886de847ab227b218f4a07b61bc337f64be/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl.metadata (2.2 kB)\nCollecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-serializinghtml>=1.1.9 from https://files.pythonhosted.org/packages/95/d6/2e0bda62b2a808070ac922d21a950aa2cb5e4fcfb87e5ff5f86bc43a2201/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-qthelp (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Obtaining dependency information for sphinxcontrib-qthelp from https://files.pythonhosted.org/packages/1f/e5/1850f3f118e95581c1e30b57028ac979badee1eb29e70ee72b0241f5a185/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl.metadata\n  Downloading sphinxcontrib_qthelp-1.0.6-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\nRequirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.20.1)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.12.1)\nCollecting alabaster<0.8,>=0.7 (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)\nCollecting imagesize>=1.3 (from sphinx>=5->numpydoc>=1.1.0->dglgo)\n  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\nRequirement already satisfied: packaging>=21.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.0->sphinx>=5->numpydoc>=1.1.0->dglgo) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\nDownloading numpydoc-1.6.0-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinx-7.2.6-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl (92 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_applehelp-1.0.7-py3-none-any.whl (120 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_devhelp-1.0.5-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_qthelp-1.0.6-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: littleutils\n  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=41431e57bd574297874230692dd86270add2f3e9202515da98edf3f545cf9b34\n  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\nSuccessfully built littleutils\nInstalling collected packages: littleutils, sphinxcontrib-jsmath, rdkit-pypi, imagesize, alabaster, outdated, ogb, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinx, numpydoc, dglgo\nSuccessfully installed alabaster-0.7.13 dglgo-0.0.2 imagesize-1.4.1 littleutils-0.2.2 numpydoc-1.6.0 ogb-1.3.6 outdated-0.2.2 rdkit-pypi-2023.3.1b1 sphinx-7.2.6 sphinxcontrib-applehelp-1.0.7 sphinxcontrib-devhelp-1.0.5 sphinxcontrib-htmlhelp-2.0.4 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.6 sphinxcontrib-serializinghtml-1.1.9\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch import nn\nfrom dgl import ops\nfrom dgl.nn.functional import edge_softmax\nimport dgl\nimport tqdm\nimport os\nimport numpy as np\nfrom torch.nn import functional as F\n\nfrom dgl import ops\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:28:09.478051Z","iopub.execute_input":"2023-12-17T11:28:09.478383Z","iopub.status.idle":"2023-12-17T11:28:13.676740Z","shell.execute_reply.started":"2023-12-17T11:28:09.478354Z","shell.execute_reply":"2023-12-17T11:28:13.675777Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"DGL backend not selected or invalid.  Assuming PyTorch for now.\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.__version__","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:28:40.468600Z","iopub.status.idle":"2023-12-17T11:28:40.468984Z","shell.execute_reply.started":"2023-12-17T11:28:40.468806Z","shell.execute_reply":"2023-12-17T11:28:40.468826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:28:40.470130Z","iopub.status.idle":"2023-12-17T11:28:40.470492Z","shell.execute_reply.started":"2023-12-17T11:28:40.470320Z","shell.execute_reply":"2023-12-17T11:28:40.470341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GATSepModule(nn.Module):\n    def __init__(self, dim, hidden_dim_multiplier, num_heads, dropout, **kwargs):\n        super().__init__()\n\n        _check_dim_and_num_heads_consistency(dim, num_heads)\n        self.dim = dim\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n\n        self.input_linear = nn.Linear(in_features=dim, out_features=dim)\n\n        self.attn_linear_u = nn.Linear(in_features=dim, out_features=num_heads)\n        self.attn_linear_v = nn.Linear(in_features=dim, out_features=num_heads, bias=False)\n        self.attn_act = nn.LeakyReLU(negative_slope=0.2)\n\n        self.feed_forward_module = FeedForwardModule(dim=dim,\n                                                     input_dim_multiplier=2,\n                                                     hidden_dim_multiplier=hidden_dim_multiplier,\n                                                     dropout=dropout)\n\n    def forward(self, graph, x):\n        x = self.input_linear(x)\n\n        attn_scores_u = self.attn_linear_u(x)\n        attn_scores_v = self.attn_linear_v(x)\n        attn_scores = ops.u_add_v(graph, attn_scores_u, attn_scores_v)\n        attn_scores = self.attn_act(attn_scores)\n        attn_probs = edge_softmax(graph, attn_scores)\n\n        x = x.reshape(-1, self.head_dim, self.num_heads)\n        message = ops.u_mul_e_sum(graph, x, attn_probs)\n        x = x.reshape(-1, self.dim)\n        message = message.reshape(-1, self.dim)\n        x = torch.cat([x, message], axis=1)\n\n        x = self.feed_forward_module(graph, x)\n\n        return x\n\n\n# class AttentionGATModule(nn.Module):\n#     def __init__(self, dimensions, multiplier_hidden, heads_count, drop_rate, **extra_args):\n#         super(AttentionGATModule, self).__init__()\n\n#         _validate_dimensions_and_heads(dimensions, heads_count)\n#         self.dimensions = dimensions\n#         self.heads_count = heads_count\n#         self.dimension_per_head = dimensions // heads_count\n\n#         self.linear_transform_input = nn.Linear(in_features=dimensions, out_features=dimensions)\n\n#         self.linear_attention_a = nn.Linear(in_features=dimensions, out_features=heads_count)\n#         self.linear_attention_b = nn.Linear(in_features=dimensions, out_features=heads_count, bias=False)\n#         self.activation_attention = nn.LeakyReLU(negative_slope=0.2)\n\n#         self.module_feedforward = FeedForwardModule(dim=dimensions,\n#                                                     multiplier_input=2,\n#                                                     multiplier_hidden=multiplier_hidden,\n#                                                     dropout_rate=drop_rate)\n\n#     def forward(self, input_graph, input_features):\n#         transformed_input = self.linear_transform_input(input_features)\n\n#         attention_scores_a = self.linear_attention_a(transformed_input)\n#         attention_scores_b = self.linear_attention_b(transformed_input)\n#         combined_attention_scores = ops.add_u_v(input_graph, attention_scores_a, attention_scores_b)\n#         combined_attention_scores = self.activation_attention(combined_attention_scores)\n#         normalized_attention = edge_softmax(input_graph, combined_attention_scores)\n\n#         transformed_input = transformed_input.view(-1, self.dimension_per_head, self.heads_count)\n#         attention_message = ops.sum_u_mul_e(input_graph, transformed_input, normalized_attention)\n#         transformed_input = transformed_input.view(-1, self.dimensions)\n#         attention_message = attention_message.view(-1, self.dimensions)\n#         concatenated_features = torch.cat([transformed_input, attention_message], axis=1)\n\n#         output_features = self.module_feedforward(input_graph, concatenated_features)\n\n#         return output_features\n","metadata":{"id":"892507ec-584e-49a7-a5be-ff93f990ad4c","execution":{"iopub.status.busy":"2023-12-17T11:28:14.678377Z","iopub.execute_input":"2023-12-17T11:28:14.678689Z","iopub.status.idle":"2023-12-17T11:28:14.691679Z","shell.execute_reply.started":"2023-12-17T11:28:14.678662Z","shell.execute_reply":"2023-12-17T11:28:14.690706Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torch import nn\n\nMODULES = {\n    'GAT-sep': [GATSepModule]\n}\n\n\nNORMALIZATION = {\n    'None': nn.Identity,\n    'LayerNorm': nn.LayerNorm,\n    'BatchNorm': nn.BatchNorm1d\n}\nclass Model(nn.Module):\n    def __init__(self, model_name, num_layers, input_dim, hidden_dim, output_dim, hidden_dim_multiplier, num_heads,\n                 normalization, dropout):\n\n        super().__init__()\n\n        normalization = NORMALIZATION[normalization]\n\n        self.input_linear = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n        self.dropout = nn.Dropout(p=dropout)\n        self.act = nn.GELU()\n\n        self.residual_modules = nn.ModuleList()\n        for _ in range(num_layers):\n            for module in MODULES[model_name]:\n                residual_module = ResidualModuleWrapper(module=module,\n                                                        normalization=normalization,\n                                                        dim=hidden_dim,\n                                                        hidden_dim_multiplier=hidden_dim_multiplier,\n                                                        num_heads=num_heads,\n                                                        dropout=dropout)\n\n                self.residual_modules.append(residual_module)\n\n        self.output_normalization = normalization(hidden_dim)\n        self.output_linear = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n\n    def forward(self, graph, x):\n        x = self.input_linear(x)\n        x = self.dropout(x)\n        x = self.act(x)\n\n        for residual_module in self.residual_modules:\n            x = residual_module(graph, x)\n\n        x = self.output_normalization(x)\n        x = self.output_linear(x).squeeze(1)\n\n        return x","metadata":{"id":"3f736d09-9981-4bbd-bf46-2cc377130e50","execution":{"iopub.status.busy":"2023-12-17T11:28:14.693396Z","iopub.execute_input":"2023-12-17T11:28:14.693770Z","iopub.status.idle":"2023-12-17T11:28:14.709659Z","shell.execute_reply.started":"2023-12-17T11:28:14.693737Z","shell.execute_reply":"2023-12-17T11:28:14.708786Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def _check_dim_and_num_heads_consistency(dim, num_heads):\n    if dim % num_heads != 0:\n        raise ValueError('Dimension mismatch: hidden_dim should be a multiple of num_heads.')","metadata":{"id":"bf30eacc-a262-4d39-b8b4-8d5781fbf88f","execution":{"iopub.status.busy":"2023-12-17T11:28:14.711005Z","iopub.execute_input":"2023-12-17T11:28:14.712538Z","iopub.status.idle":"2023-12-17T11:28:14.725156Z","shell.execute_reply.started":"2023-12-17T11:28:14.712511Z","shell.execute_reply":"2023-12-17T11:28:14.724296Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Dataset:\n    def __init__(self, name, add_self_loops=False, device='cpu', use_sgc_features=False, use_identity_features=False,\n                 use_adjacency_features=False, do_not_use_original_features=False):\n\n        if do_not_use_original_features and not any([use_sgc_features, use_identity_features, use_adjacency_features]):\n            raise ValueError('If original node features are not used, at least one of the arguments '\n                             'use_sgc_features, use_identity_features, use_adjacency_features should be used.')\n\n        print('Preparing data...')\n        data = np.load(os.path.join('/kaggle/input/squirrel', f'{name.replace(\"-\", \"_\")}.npz'))\n        node_features = torch.tensor(data['node_features'])\n        labels = torch.tensor(data['node_labels'])\n        edges = torch.tensor(data['edges'])\n\n        graph = dgl.graph((edges[:, 0], edges[:, 1]), num_nodes=len(node_features), idtype=torch.int)\n\n        if 'directed' not in name:\n            graph = dgl.to_bidirected(graph)\n\n        if add_self_loops:\n            graph = dgl.add_self_loop(graph)\n\n        num_classes = len(labels.unique())\n        num_targets = 1 if num_classes == 2 else num_classes\n        if num_targets == 1:\n            labels = labels.float()\n\n        train_masks = torch.tensor(data['train_masks'])\n        val_masks = torch.tensor(data['val_masks'])\n        test_masks = torch.tensor(data['test_masks'])\n\n        train_idx_list = [torch.where(train_mask)[0] for train_mask in train_masks]\n        val_idx_list = [torch.where(val_mask)[0] for val_mask in val_masks]\n        test_idx_list = [torch.where(test_mask)[0] for test_mask in test_masks]\n\n        node_features = self.augment_node_features(graph=graph,\n                                                   node_features=node_features,\n                                                   use_sgc_features=use_sgc_features,\n                                                   use_identity_features=use_identity_features,\n                                                   use_adjacency_features=use_adjacency_features,\n                                                   do_not_use_original_features=do_not_use_original_features)\n\n        self.name = name\n        self.device = device\n\n        self.graph = graph.to(device)\n        self.node_features = node_features.to(device)\n        self.labels = labels.to(device)\n\n        self.train_idx_list = [train_idx.to(device) for train_idx in train_idx_list]\n        self.val_idx_list = [val_idx.to(device) for val_idx in val_idx_list]\n        self.test_idx_list = [test_idx.to(device) for test_idx in test_idx_list]\n        self.num_data_splits = len(train_idx_list)\n        self.cur_data_split = 0\n\n        self.num_node_features = node_features.shape[1]\n        self.num_targets = num_targets\n\n        self.loss_fn = F.binary_cross_entropy_with_logits if num_targets == 1 else F.cross_entropy\n        self.metric = 'ROC AUC' if num_targets == 1 else 'accuracy'\n\n    @property\n    def train_idx(self):\n        return self.train_idx_list[self.cur_data_split]\n\n    @property\n    def val_idx(self):\n        return self.val_idx_list[self.cur_data_split]\n\n    @property\n    def test_idx(self):\n        return self.test_idx_list[self.cur_data_split]\n\n    def next_data_split(self):\n        self.cur_data_split = (self.cur_data_split + 1) % self.num_data_splits\n\n    def compute_metrics(self, logits):\n        if self.num_targets == 1:\n            train_metric = roc_auc_score(y_true=self.labels[self.train_idx].cpu().numpy(),\n                                         y_score=logits[self.train_idx].cpu().numpy()).item()\n\n            val_metric = roc_auc_score(y_true=self.labels[self.val_idx].cpu().numpy(),\n                                       y_score=logits[self.val_idx].cpu().numpy()).item()\n\n            test_metric = roc_auc_score(y_true=self.labels[self.test_idx].cpu().numpy(),\n                                        y_score=logits[self.test_idx].cpu().numpy()).item()\n\n        else:\n            preds = logits.argmax(axis=1)\n            train_metric = (preds[self.train_idx] == self.labels[self.train_idx]).float().mean().item()\n            val_metric = (preds[self.val_idx] == self.labels[self.val_idx]).float().mean().item()\n            test_metric = (preds[self.test_idx] == self.labels[self.test_idx]).float().mean().item()\n\n        metrics = {\n            f'train {self.metric}': train_metric,\n            f'val {self.metric}': val_metric,\n            f'test {self.metric}': test_metric\n        }\n\n        return metrics\n\n    @staticmethod\n    def augment_node_features(graph, node_features, use_sgc_features, use_identity_features, use_adjacency_features,\n                              do_not_use_original_features):\n\n        n = graph.num_nodes()\n        original_node_features = node_features\n\n        if do_not_use_original_features:\n            node_features = torch.tensor([[] for _ in range(n)])\n\n        if use_sgc_features:\n            sgc_features = Dataset.compute_sgc_features(graph, original_node_features)\n            node_features = torch.cat([node_features, sgc_features], axis=1)\n\n        if use_identity_features:\n            node_features = torch.cat([node_features, torch.eye(n)], axis=1)\n\n        if use_adjacency_features:\n            graph_without_self_loops = dgl.remove_self_loop(graph)\n            adj_matrix = graph_without_self_loops.adjacency_matrix().to_dense()\n            node_features = torch.cat([node_features, adj_matrix], axis=1)\n\n        return node_features\n\n    @staticmethod\n    def compute_sgc_features(graph, node_features, num_props=5):\n        graph = dgl.remove_self_loop(graph)\n        graph = dgl.add_self_loop(graph)\n\n        degrees = graph.out_degrees().float()\n        degree_edge_products = ops.u_mul_v(graph, degrees, degrees)\n        norm_coefs = 1 / degree_edge_products ** 0.5\n\n        for _ in range(num_props):\n            node_features = ops.u_mul_e_sum(graph, node_features, norm_coefs)\n\n        return node_features","metadata":{"id":"c18b0dd0-1a6f-43cb-a11c-2b033d8bb4d7","execution":{"iopub.status.busy":"2023-12-17T11:28:14.726680Z","iopub.execute_input":"2023-12-17T11:28:14.727285Z","iopub.status.idle":"2023-12-17T11:28:14.756509Z","shell.execute_reply.started":"2023-12-17T11:28:14.727250Z","shell.execute_reply":"2023-12-17T11:28:14.755584Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")","metadata":{"id":"bc4488b2-2eeb-455d-9d30-d81c1c1519bf","execution":{"iopub.status.busy":"2023-12-17T11:28:14.757691Z","iopub.execute_input":"2023-12-17T11:28:14.758040Z","iopub.status.idle":"2023-12-17T11:28:14.770142Z","shell.execute_reply.started":"2023-12-17T11:28:14.758007Z","shell.execute_reply":"2023-12-17T11:28:14.769346Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = Dataset(name=\"squirrel\",\n                 add_self_loops=True,\n                 device=device,\n                 use_sgc_features=False,\n                 use_identity_features=False,\n                 use_adjacency_features=False,\n                 do_not_use_original_features=False)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47ac5e49-656c-4bfe-823f-4b9b783051d3","outputId":"ca434010-a3dc-49ed-ebfe-101928b63639","execution":{"iopub.status.busy":"2023-12-17T11:28:14.774074Z","iopub.execute_input":"2023-12-17T11:28:14.774437Z","iopub.status.idle":"2023-12-17T11:28:20.291336Z","shell.execute_reply.started":"2023-12-17T11:28:14.774411Z","shell.execute_reply":"2023-12-17T11:28:20.290180Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Preparing data...\n","output_type":"stream"}]},{"cell_type":"code","source":"class ResidualModuleWrapper(nn.Module):\n    def __init__(self, module, normalization, dim, **kwargs):\n        super().__init__()\n        self.normalization = normalization(dim)\n        self.module = module(dim=dim, **kwargs)\n\n    def forward(self, graph, x):\n        x_res = self.normalization(x)\n        x_res = self.module(graph, x_res)\n        x = x + x_res\n\n        return x\n\n\nclass FeedForwardModule(nn.Module):\n    def __init__(self, dim, hidden_dim_multiplier, dropout, input_dim_multiplier=1, **kwargs):\n        super().__init__()\n        input_dim = int(dim * input_dim_multiplier)\n        hidden_dim = int(dim * hidden_dim_multiplier)\n        self.linear_1 = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n        self.dropout_1 = nn.Dropout(p=dropout)\n        self.act = nn.GELU()\n        self.linear_2 = nn.Linear(in_features=hidden_dim, out_features=dim)\n        self.dropout_2 = nn.Dropout(p=dropout)\n\n    def forward(self, graph, x):\n        x = self.linear_1(x)\n        x = self.dropout_1(x)\n        x = self.act(x)\n        x = self.linear_2(x)\n        x = self.dropout_2(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:28:20.292711Z","iopub.execute_input":"2023-12-17T11:28:20.293101Z","iopub.status.idle":"2023-12-17T11:28:20.303247Z","shell.execute_reply.started":"2023-12-17T11:28:20.293062Z","shell.execute_reply":"2023-12-17T11:28:20.302260Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = Model(model_name=\"GAT-sep\",num_layers=5,input_dim=dataset.num_node_features,\n             hidden_dim=512,output_dim=dataset.num_targets,\n             hidden_dim_multiplier=1,num_heads=8,normalization='BatchNorm',\n             dropout=0.2)","metadata":{"id":"3f6fee87-b93e-4104-b4a0-a11f7a31d522","execution":{"iopub.status.busy":"2023-12-17T11:28:20.304470Z","iopub.execute_input":"2023-12-17T11:28:20.304759Z","iopub.status.idle":"2023-12-17T11:28:20.376144Z","shell.execute_reply.started":"2023-12-17T11:28:20.304734Z","shell.execute_reply":"2023-12-17T11:28:20.375489Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train_step(model, dataset, optimizer, scheduler, scaler, amp=False):\n    model.train()\n\n    with autocast(enabled=amp):\n        logits = model(graph=dataset.graph, x=dataset.node_features)\n        loss = dataset.loss_fn(input=logits[dataset.train_idx], target=dataset.labels[dataset.train_idx])\n\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n    optimizer.zero_grad()\n    scheduler.step()\n\n\n@torch.no_grad()\ndef evaluate(model, dataset, amp=False):\n    model.eval()\n    with autocast(enabled=amp):\n        logits = model(graph=dataset.graph, x=dataset.node_features)\n    metrics = dataset.compute_metrics(logits)\n    return metrics","metadata":{"id":"022895a2-1464-401e-adbd-1d43b33a57bf","execution":{"iopub.status.busy":"2023-12-17T11:28:20.377064Z","iopub.execute_input":"2023-12-17T11:28:20.377311Z","iopub.status.idle":"2023-12-17T11:28:20.384671Z","shell.execute_reply.started":"2023-12-17T11:28:20.377273Z","shell.execute_reply":"2023-12-17T11:28:20.383797Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_parameter_groups(model):\n    no_weight_decay_names = ['bias', 'normalization', 'label_embeddings']\n\n    parameter_groups = [\n        {\n            'params': [param for name, param in model.named_parameters()\n                       if not any(no_weight_decay_name in name for no_weight_decay_name in no_weight_decay_names)]\n        },\n        {\n            'params': [param for name, param in model.named_parameters()\n                       if any(no_weight_decay_name in name for no_weight_decay_name in no_weight_decay_names)],\n            'weight_decay': 0\n        },\n    ]\n\n    return parameter_groups\ndef get_lr_scheduler_with_warmup(optimizer, num_warmup_steps=None, num_steps=None, warmup_proportion=None,\n                                 last_step=-1):\n\n    if num_warmup_steps is None and (num_steps is None or warmup_proportion is None):\n        raise ValueError('Either num_warmup_steps or num_steps and warmup_proportion should be provided.')\n\n    if num_warmup_steps is None:\n        num_warmup_steps = int(num_steps * warmup_proportion)\n\n    def get_lr_multiplier(step):\n        if step < num_warmup_steps:\n            return (step + 1) / (num_warmup_steps + 1)\n        else:\n            return 1\n\n    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_multiplier, last_epoch=last_step)\n\n    return lr_scheduler","metadata":{"id":"b59c4eae-6670-42b8-a783-df1df290e39f","execution":{"iopub.status.busy":"2023-12-17T11:28:20.385721Z","iopub.execute_input":"2023-12-17T11:28:20.385976Z","iopub.status.idle":"2023-12-17T11:28:20.401104Z","shell.execute_reply.started":"2023-12-17T11:28:20.385953Z","shell.execute_reply":"2023-12-17T11:28:20.400118Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# torch.onnx.export(model, (dataset.graph.adj_tensors('csc'),dataset.node_features), 'gt-sep.onnx', input_names=[\"features\"], output_names=[\"logits\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:28:20.402193Z","iopub.execute_input":"2023-12-17T11:28:20.402542Z","iopub.status.idle":"2023-12-17T11:28:20.412772Z","shell.execute_reply.started":"2023-12-17T11:28:20.402516Z","shell.execute_reply":"2023-12-17T11:28:20.411904Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.to(torch.device(\"cuda:0\"))","metadata":{"id":"d85de6c6-38d5-43c9-9d6f-de4241edf984","outputId":"5488bc40-4627-40f7-e905-271f9841646e","execution":{"iopub.status.busy":"2023-12-17T11:28:20.413720Z","iopub.execute_input":"2023-12-17T11:28:20.413976Z","iopub.status.idle":"2023-12-17T11:28:20.441671Z","shell.execute_reply.started":"2023-12-17T11:28:20.413953Z","shell.execute_reply":"2023-12-17T11:28:20.440741Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Model(\n  (input_linear): Linear(in_features=2089, out_features=512, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (act): GELU(approximate='none')\n  (residual_modules): ModuleList(\n    (0-4): 5 x ResidualModuleWrapper(\n      (normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (module): GATSepModule(\n        (input_linear): Linear(in_features=512, out_features=512, bias=True)\n        (attn_linear_u): Linear(in_features=512, out_features=8, bias=True)\n        (attn_linear_v): Linear(in_features=512, out_features=8, bias=False)\n        (attn_act): LeakyReLU(negative_slope=0.2)\n        (feed_forward_module): FeedForwardModule(\n          (linear_1): Linear(in_features=1024, out_features=512, bias=True)\n          (dropout_1): Dropout(p=0.2, inplace=False)\n          (act): GELU(approximate='none')\n          (linear_2): Linear(in_features=512, out_features=512, bias=True)\n          (dropout_2): Dropout(p=0.2, inplace=False)\n        )\n      )\n    )\n  )\n  (output_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (output_linear): Linear(in_features=512, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"parameter_groups = get_parameter_groups(model)\noptimizer = torch.optim.AdamW(parameter_groups, lr=3e-5, weight_decay=0)\nscheduler = get_lr_scheduler_with_warmup(optimizer=optimizer, num_warmup_steps=None,\n                                                 num_steps=500, warmup_proportion=0)","metadata":{"id":"2c413707-d09b-418d-aefb-8095dd8b1b89","execution":{"iopub.status.busy":"2023-12-17T11:28:20.442741Z","iopub.execute_input":"2023-12-17T11:28:20.443514Z","iopub.status.idle":"2023-12-17T11:28:20.449129Z","shell.execute_reply.started":"2023-12-17T11:28:20.443487Z","shell.execute_reply":"2023-12-17T11:28:20.448210Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for run in range(1):\n    with tqdm.tqdm(total=500, desc=f'Run {run}', disable=False) as progress_bar:\n                for step in range(1, 500 + 1):\n                    train_step(model=model, dataset=dataset, optimizer=optimizer, scheduler=scheduler,scaler= GradScaler(enabled=True))\n                    metrics = evaluate(model=model, dataset=dataset, amp=False)\n                    progress_bar.update()\n                    progress_bar.set_postfix({metric: f'{value:.2f}' for metric, value in metrics.items()})","metadata":{"id":"5937f5a4-c27f-430d-9074-a3bcc3d4b849","outputId":"bf074513-d176-44d4-c11d-de3b1fa45026","execution":{"iopub.status.busy":"2023-12-17T11:28:20.450180Z","iopub.execute_input":"2023-12-17T11:28:20.450605Z","iopub.status.idle":"2023-12-17T11:28:40.467652Z","shell.execute_reply.started":"2023-12-17T11:28:20.450565Z","shell.execute_reply":"2023-12-17T11:28:40.465936Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Run 0:  21%|██▏       | 107/500 [00:18<01:09,  5.64it/s, train accuracy=0.92, val accuracy=0.41, test accuracy=0.41]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m                 \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGradScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43menabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m                 metrics \u001b[38;5;241m=\u001b[39m evaluate(model\u001b[38;5;241m=\u001b[39mmodel, dataset\u001b[38;5;241m=\u001b[39mdataset, amp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m                 progress_bar\u001b[38;5;241m.\u001b[39mupdate()\n","Cell \u001b[0;32mIn[13], line 9\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataset, optimizer, scheduler, scaler, amp)\u001b[0m\n\u001b[1;32m      6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mloss_fn(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlogits[dataset\u001b[38;5;241m.\u001b[39mtrain_idx], target\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlabels[dataset\u001b[38;5;241m.\u001b[39mtrain_idx])\n\u001b[1;32m      8\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m----> 9\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:370\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:290\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 290\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    161\u001b[0m         group,\n\u001b[1;32m    162\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         state_steps,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 321\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:549\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[0;32m--> 549\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    551\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n\u001b[1;32m    553\u001b[0m     bias_correction2_sqrt \u001b[38;5;241m=\u001b[39m [_dispatch_sqrt(bc) \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction2]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:549\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[0;32m--> 549\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    551\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n\u001b[1;32m    553\u001b[0m     bias_correction2_sqrt \u001b[38;5;241m=\u001b[39m [_dispatch_sqrt(bc) \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction2]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"87453cce-d955-4d65-8747-f0259bdb893e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}